{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "automated_essay_scoring.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg4GyGs/1fhFP5w7MK59eU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gail529/AES/blob/main/automated_essay_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTILa78Y3xVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed58be79-b409-4dc5-fd2e-ed1c6ea83bbb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        " \n",
        "import re\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  \n",
        "from gensim.models import Word2Vec\n",
        " \n",
        " \n",
        "#essay preprocessing \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "#training the neural network \n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import keras.backend as K"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "1_-bDXNbIUpe",
        "outputId": "6078878d-e91f-4a80-9a91-8c71cc00b6db"
      },
      "source": [
        "essay_data= pd.read_excel('/content/training_set_rel3.xlsx',usecols=['essay_id','essay','domain1_score'])\n",
        "essay_data.head(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id                                              essay  domain1_score\n",
              "0         1  Dear local newspaper, I think effects computer...            8.0\n",
              "1         2  Dear @CAPS1 @CAPS2, I believe that using compu...            9.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpkl7yetIdWD",
        "outputId": "cc17191b-282f-48c0-eed3-d244224e8958"
      },
      "source": [
        "x=essay_data['essay']\n",
        "y=essay_data['domain1_score']\n",
        "len(x) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB5IxYDird9g"
      },
      "source": [
        "essay_data['domain1_score'] = essay_data['domain1_score'].fillna(essay_data['domain1_score'].mean())\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-kv1D3corBL",
        "outputId": "f0ee97f6-61b6-44d6-c635-ed022a563036"
      },
      "source": [
        "essay_data.isnull().sum().sum()\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DBRO26_fkMI",
        "outputId": "be6b4e52-f5fe-433d-9c7d-b5f2d43771c6"
      },
      "source": [
        "np.any(np.isnan(y).sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM5Xp0rbEaC_"
      },
      "source": [
        "def sent_tokenize(text):\n",
        "    stripped_essay = text.strip()\n",
        "    \n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(stripped_essay)\n",
        "    \n",
        "    tokenized_sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        clean_sentence = re.sub(\"[^a-zA-Z0-9]\",\" \", raw_sentence)\n",
        "        words = clean_sentence.lower().split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "        tokenized_sentences.append(words)\n",
        "\n",
        "    return tokenized_sentences\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es33b9LNUUla"
      },
      "source": [
        "cleaned_essays=[]\n",
        "for i in range(0,len(x)):\n",
        "    essay=x[i]\n",
        "    cleaned_essays.append(sent_tokenize(essay))\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7UIo0SnAWma"
      },
      "source": [
        "sentences=[]\n",
        "for essay in x:\n",
        "    sentences += sent_tokenize(essay)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rKwV3LzB1Mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d63b42d-193a-413b-f802-021cc216ea35"
      },
      "source": [
        "sentences[100]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['result', 'computers', 'would', 'improve', 'way', 'learn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt1qTaNQ_Dva"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvMn_Q2JLeTd",
        "outputId": "b6d83d12-aac4-42b7-d965-db7cbe7fb297"
      },
      "source": [
        "text_dim = 300\n",
        "print(\"Training Word2Vec model...\")\n",
        "wordvec_model = Word2Vec(sentences, size=text_dim, window=5, min_count=3, workers=4, sg=1)\n",
        "print(\"Word2Vec model created.\")\n",
        "print(\"%d unique words represented by %d dimensional vectors\" % (len(wordvec_model.wv.vocab), text_dim))\n",
        "wordvec_model.save('wordvec_model')\n",
        "print(\"Word2Vec model saved.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Word2Vec model...\n",
            "Word2Vec model created.\n",
            "13134 unique words represented by 300 dimensional vectors\n",
            "Word2Vec model saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gaRkCN1TBy-"
      },
      "source": [
        "def clean_essays(essay):\n",
        "    clean_essay= re.sub(\"[^a-zA-Z]\", \" \",essay)\n",
        "    words = essay.lower().split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if not w in stops]\n",
        "    return (words)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmRZvEdiSh6s"
      },
      "source": [
        "cleaned_essays = []\n",
        "for essay in x:\n",
        "        cleaned_essays.append(clean_essays(essay))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIwuz6r8PgLc"
      },
      "source": [
        "def create_average_vec(essay):\n",
        "    average = np.zeros((text_dim,), dtype='float32')\n",
        "    num_words = 0.\n",
        "    for word in essay:\n",
        "        if word in wordvec_model.wv.vocab:\n",
        "            average = np.add(average, wordvec_model.wv[word])\n",
        "            num_words += 1.\n",
        "    if num_words != 0.:\n",
        "        average = np.divide(average, num_words)\n",
        "    return average"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBIOCDifPoMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981d7b54-b580-4654-e302-2f2c140aa032"
      },
      "source": [
        "cleaned_vec = np.zeros((len(x),text_dim), dtype=\"float32\")  \n",
        "for i in range(len(cleaned_essays)):\n",
        "    cleaned_vec[i] = create_average_vec(cleaned_essays[i])\n",
        "\n",
        "print(\"Word vectors for all essays in the training data set are of shape:\", cleaned_vec.shape)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word vectors for all essays in the training data set are of shape: (12978, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23_vYXi1ibA9",
        "outputId": "baf4f7dc-df9c-4240-8274-55b76da2d9c2"
      },
      "source": [
        "data_split=0.8\n",
        "train_samples=int(len(cleaned_vec)*data_split)\n",
        "\n",
        "x_train = np.array(cleaned_vec[:train_samples])\n",
        "x_test = np.array(cleaned_vec[train_samples:])\n",
        "y_train = np.array(y[:train_samples])\n",
        "y_test = np.array(y[train_samples:])\n",
        "\n",
        "print(\"x_train\" ,len(x_train))\n",
        "print(\"x_test\" ,len(x_test))\n",
        "print(\"y_train\" ,len(y_train))\n",
        "print(\"y_test\" ,len(y_test))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train 10382\n",
            "x_test 2596\n",
            "y_train 10382\n",
            "y_test 2596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDFg8poKe_0I",
        "outputId": "7feb12a8-7c57-4b11-f0ab-552cd1cfb34d"
      },
      "source": [
        "#np.any(np.isnan(x_train))\n",
        "#np.any(np.isnan(x_test))\n",
        "#np.any(np.isnan(y_train))\n",
        "np.any(np.isnan(y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tt05pTQUQOA"
      },
      "source": [
        "cleaned_essays[89]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kDonCQA3ToHV",
        "outputId": "b77828db-0146-4a6b-d054-09498855f68c"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "\n",
        "lstm_model = get_model3()\n",
        "lstm_model.fit(x_train, y_train, batch_size=500, epochs=20)\n",
        "y_pred = lstm_model.predict(x_test)\n",
        "lstm_model.save('final_lstm.h5')\n",
        "\n",
        "# Round y_pred to the nearest integer.\n",
        "y_pred = np.around(y_pred)\n",
        "\n",
        "# Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))\n",
        "\n",
        "\n",
        "# Plot history: MAE\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lstm_model.history['loss'], label='MAE (training data)')\n",
        "plt.plot(lstm_model.history['val_loss'], label='MAE (validation data)')\n",
        "plt.title('MAE for AES')\n",
        "plt.ylabel('MAE value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_16 (LSTM)               (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "21/21 [==============================] - 6s 75ms/step - loss: 16.8400 - mae: 3.1315\n",
            "Epoch 2/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.6003 - mae: 2.4814\n",
            "Epoch 3/20\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 12.6740 - mae: 2.4946\n",
            "Epoch 4/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.6269 - mae: 2.4898\n",
            "Epoch 5/20\n",
            "21/21 [==============================] - 2s 73ms/step - loss: 12.9499 - mae: 2.5109\n",
            "Epoch 6/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.9211 - mae: 2.5167\n",
            "Epoch 7/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.7134 - mae: 2.4984\n",
            "Epoch 8/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.7329 - mae: 2.5037\n",
            "Epoch 9/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.9163 - mae: 2.5224\n",
            "Epoch 10/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.9512 - mae: 2.5179\n",
            "Epoch 11/20\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 13.0769 - mae: 2.5359\n",
            "Epoch 12/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.9411 - mae: 2.5168\n",
            "Epoch 13/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.2169 - mae: 2.4587\n",
            "Epoch 14/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.7293 - mae: 2.4906\n",
            "Epoch 15/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.7048 - mae: 2.4951\n",
            "Epoch 16/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.5914 - mae: 2.4862\n",
            "Epoch 17/20\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 12.6769 - mae: 2.4979\n",
            "Epoch 18/20\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 12.3767 - mae: 2.4635\n",
            "Epoch 19/20\n",
            "21/21 [==============================] - 2s 74ms/step - loss: 12.8483 - mae: 2.5125\n",
            "Epoch 20/20\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 12.9279 - mae: 2.5148\n",
            "Kappa Score: 2.5698828580722477e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c7dbd4666ccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Plot history: MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MAE (training data)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MAE (validation data)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MAE for AES'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_16xPRvcbD5"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_model2():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_model3():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def get_model4():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHIzH4lncdl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a611196-066b-4d56-fc24-e6204ea6ce48"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "\n",
        "lstm_model = get_model()\n",
        "lstm_model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
        "y_pred = lstm_model.predict(x_test)\n",
        "lstm_model.save('final_lstm.h5')\n",
        "\n",
        "# Round y_pred to the nearest integer.\n",
        "y_pred = np.around(y_pred)\n",
        "\n",
        "# Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "104/104 [==============================] - 7s 27ms/step - loss: 14.4896 - accuracy: 0.1276\n",
            "Epoch 2/20\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 12.8384 - accuracy: 0.1661\n",
            "Epoch 3/20\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 12.7571 - accuracy: 0.1659\n",
            "Epoch 4/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.9601 - accuracy: 0.1615\n",
            "Epoch 5/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.8610 - accuracy: 0.1595\n",
            "Epoch 6/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.6435 - accuracy: 0.1710\n",
            "Epoch 7/20\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 12.8210 - accuracy: 0.1615\n",
            "Epoch 8/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.8186 - accuracy: 0.1638\n",
            "Epoch 9/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.7189 - accuracy: 0.1678\n",
            "Epoch 10/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.4793 - accuracy: 0.1618\n",
            "Epoch 11/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.5963 - accuracy: 0.1683\n",
            "Epoch 12/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.7731 - accuracy: 0.1712\n",
            "Epoch 13/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.7877 - accuracy: 0.1626\n",
            "Epoch 14/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.3152 - accuracy: 0.1686\n",
            "Epoch 15/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.8506 - accuracy: 0.1705\n",
            "Epoch 16/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.5760 - accuracy: 0.1690\n",
            "Epoch 17/20\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 12.9640 - accuracy: 0.1589\n",
            "Epoch 18/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.7531 - accuracy: 0.1681\n",
            "Epoch 19/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.5611 - accuracy: 0.1688\n",
            "Epoch 20/20\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 12.7819 - accuracy: 0.1631\n",
            "Kappa Score: 2.5698828580722477e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-brmjdSsW07",
        "outputId": "4aea860a-d90b-4ab4-9608-460f8d553ead"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "\n",
        "lstm_model = get_model2()\n",
        "lstm_model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
        "y_pred = lstm_model.predict(x_test)\n",
        "lstm_model.save('final_lstm2.h5')\n",
        "\n",
        "# Round y_pred to the nearest integer.\n",
        "y_pred = np.around(y_pred)\n",
        "\n",
        "# Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "104/104 [==============================] - 8s 31ms/step - loss: 6.9695 - mae: 1.8185\n",
            "Epoch 2/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 2.2457 - mae: 1.1317\n",
            "Epoch 3/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 2.0415 - mae: 1.0507\n",
            "Epoch 4/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.8351 - mae: 0.9984\n",
            "Epoch 5/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.6934 - mae: 0.9725\n",
            "Epoch 6/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.6742 - mae: 0.9556\n",
            "Epoch 7/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.5857 - mae: 0.9226\n",
            "Epoch 8/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.4793 - mae: 0.9087\n",
            "Epoch 9/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.3904 - mae: 0.8824\n",
            "Epoch 10/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.3739 - mae: 0.8700\n",
            "Epoch 11/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.3032 - mae: 0.8606\n",
            "Epoch 12/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.3015 - mae: 0.8589\n",
            "Epoch 13/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.2486 - mae: 0.8333\n",
            "Epoch 14/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.2454 - mae: 0.8420\n",
            "Epoch 15/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.1784 - mae: 0.8183\n",
            "Epoch 16/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.1857 - mae: 0.8194\n",
            "Epoch 17/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.1523 - mae: 0.8101\n",
            "Epoch 18/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.1840 - mae: 0.8131\n",
            "Epoch 19/20\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1.1208 - mae: 0.7926\n",
            "Epoch 20/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.1623 - mae: 0.7989\n",
            "Kappa Score: 0.014519219835083863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9i7GUjicHgv",
        "outputId": "8610b74f-2406-45a4-96e2-9f9e96a67680"
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
        "    \n",
        "\n",
        "lstm_model = get_model4()\n",
        "lstm_model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
        "y_pred = lstm_model.predict(x_test)\n",
        "lstm_model.save('final_lstm4.h5')\n",
        "\n",
        "# Round y_pred to the nearest integer.\n",
        "y_pred = np.around(y_pred)\n",
        "\n",
        "# Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_8 (LSTM)                (None, 1, 300)            721200    \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 814,705\n",
            "Trainable params: 814,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "104/104 [==============================] - 7s 29ms/step - loss: 14.0811 - mae: 2.6886\n",
            "Epoch 2/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.9203 - mae: 2.5200\n",
            "Epoch 3/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.7562 - mae: 2.5074\n",
            "Epoch 4/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 13.0556 - mae: 2.5309\n",
            "Epoch 5/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.5212 - mae: 2.4859\n",
            "Epoch 6/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.6284 - mae: 2.4928\n",
            "Epoch 7/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.5253 - mae: 2.4738\n",
            "Epoch 8/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.7611 - mae: 2.4924\n",
            "Epoch 9/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.4468 - mae: 2.4729\n",
            "Epoch 10/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.5483 - mae: 2.4883\n",
            "Epoch 11/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 13.0675 - mae: 2.5334\n",
            "Epoch 12/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.8560 - mae: 2.5019\n",
            "Epoch 13/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.8090 - mae: 2.5061\n",
            "Epoch 14/20\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 12.5188 - mae: 2.4841\n",
            "Epoch 15/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 13.0227 - mae: 2.5296\n",
            "Epoch 16/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.7223 - mae: 2.5038\n",
            "Epoch 17/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.8763 - mae: 2.5255\n",
            "Epoch 18/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.7137 - mae: 2.4969\n",
            "Epoch 19/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.5405 - mae: 2.4759\n",
            "Epoch 20/20\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 12.8727 - mae: 2.5094\n",
            "Kappa Score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}